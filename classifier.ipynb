{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import re\n",
    "import torchxrayvision as xrv\n",
    "import torchvision\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using standard dataset\n",
    "def create_dataloaders(jhu_image_dir=None,ucsf_image_dir=None,washu_image_dir=None,jhu_label=None,ucsf_label=None,washu_label=None,replicate=2):\n",
    "    \n",
    "    jhu_odi=np.load(jhu_label)\n",
    "    jhu_odi=np.array([item>40 for item in jhu_odi],dtype=np.int32)\n",
    "    jhu_odi=list(np.repeat(jhu_odi,replicate))\n",
    "    jhu_images=[os.path.join(jhu_image_dir,img_folder,img) for img_folder in sorted(os.listdir(jhu_image_dir)) for img in os.listdir(os.path.join(jhu_image_dir,img_folder)) ]\n",
    "    \n",
    "    ucsf_odi=np.load(ucsf_label)\n",
    "    ucsf_odi=np.array([item>40 for item in ucsf_odi],dtype=np.int32)\n",
    "    ucsf_odi=list(np.repeat(ucsf_odi,replicate))\n",
    "    ucsf_images=[os.path.join(ucsf_image_dir,img_folder,img) for img_folder in sorted(os.listdir(ucsf_image_dir)) for img in os.listdir(os.path.join(ucsf_image_dir,img_folder)) ]\n",
    "    \n",
    "    washu_odi=np.load(washu_label)\n",
    "    washu_odi=np.array([item>40 for item in washu_odi],dtype=np.int32)\n",
    "    washu_odi=list(np.repeat(washu_odi,replicate))\n",
    "    washu_images=[os.path.join(washu_image_dir,img_folder,img) for img_folder in sorted(os.listdir(washu_image_dir)) for img in os.listdir(os.path.join(washu_image_dir,img_folder)) ]\n",
    "    \n",
    "    images=jhu_images+ucsf_images+washu_images\n",
    "    scores=jhu_odi+ucsf_odi+washu_odi\n",
    "    \n",
    "    print(len(images))\n",
    "    print(len(scores))\n",
    "    \n",
    "    return images,scores\n",
    "\n",
    "images,scores=create_dataloaders(jhu_image_dir='/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_JHU/JPG',ucsf_image_dir='/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_UCSF/UCSF',washu_image_dir='/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_WashU/final_images',jhu_label='/home/blu/ai/xray_score/JHU_UCSF_WASHU/jhu.npy',ucsf_label='/home/blu/ai/xray_score/JHU_UCSF_WASHU/ucsf.npy',washu_label='/home/blu/ai/xray_score/JHU_UCSF_WASHU/washu.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using augmented dataset\n",
    "def create_aug_dataloaders(jhu_image_dir=None,ucsf_image_dir=None,washu_image_dir=None,jhu_label=None,ucsf_label=None,washu_label=None,replicate=10):\n",
    "    \n",
    "    jhu_odi=np.load(jhu_label)\n",
    "    jhu_odi=np.array([item>40 for item in jhu_odi],dtype=np.int32)\n",
    "    jhu_odi=list(np.repeat(jhu_odi,replicate))\n",
    "    jhu_images=[os.path.join(jhu_image_dir,img_folder,img) for img_folder in sorted(os.listdir(jhu_image_dir)) for img in os.listdir(os.path.join(jhu_image_dir,img_folder)) ]\n",
    "    \n",
    "    ucsf_odi=np.load(ucsf_label)\n",
    "    ucsf_odi=np.array([item>40 for item in ucsf_odi],dtype=np.int32)\n",
    "    ucsf_odi=list(np.repeat(ucsf_odi,replicate))\n",
    "    ucsf_images=[os.path.join(ucsf_image_dir,img_folder,img) for img_folder in sorted(os.listdir(ucsf_image_dir)) for img in os.listdir(os.path.join(ucsf_image_dir,img_folder)) ]\n",
    "    \n",
    "    washu_odi=np.load(washu_label)\n",
    "    washu_odi=np.array([item>40 for item in washu_odi],dtype=np.int32)\n",
    "    washu_odi=list(np.repeat(washu_odi,replicate))\n",
    "    washu_images=[os.path.join(washu_image_dir,img_folder,img) for img_folder in sorted(os.listdir(washu_image_dir)) for img in os.listdir(os.path.join(washu_image_dir,img_folder)) ]\n",
    "    \n",
    "    images=jhu_images+ucsf_images+washu_images\n",
    "    scores=jhu_odi+ucsf_odi+washu_odi\n",
    "    \n",
    "    print(len(images))\n",
    "    print(len(scores))\n",
    "    \n",
    "    return images,scores\n",
    "\n",
    "images,scores=create_aug_dataloaders(jhu_image_dir='/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_JHU/augmented_images',ucsf_image_dir='/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_UCSF/augmented_images',washu_image_dir='/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_WashU/augmented_images',jhu_label='/home/blu/ai/xray_score/JHU_UCSF_WASHU/jhu.npy',ucsf_label='/home/blu/ai/xray_score/JHU_UCSF_WASHU/ucsf.npy',washu_label='/home/blu/ai/xray_score/JHU_UCSF_WASHU/washu.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using augmented dataset\n",
    "def create_aug_dataloaders_resnet(jhu_image_dir=None,ucsf_image_dir=None,washu_image_dir=None,jhu_label=None,ucsf_label=None,washu_label=None,replicate=10):\n",
    "    \n",
    "    jhu_odi=np.load(jhu_label)\n",
    "    jhu_odi=np.array([item>40 for item in jhu_odi],dtype=np.int32)\n",
    "    jhu_odi=list(np.repeat(jhu_odi,replicate))\n",
    "    jhu_images=[os.path.join(jhu_image_dir,img_folder,img) for img_folder in sorted(os.listdir(jhu_image_dir)) for img in os.listdir(os.path.join(jhu_image_dir,img_folder)) ]\n",
    "    \n",
    "    ucsf_odi=np.load(ucsf_label)\n",
    "    ucsf_odi=np.array([item>40 for item in ucsf_odi],dtype=np.int32)\n",
    "    ucsf_odi=list(np.repeat(ucsf_odi,replicate))\n",
    "    ucsf_images=[os.path.join(ucsf_image_dir,img_folder,img) for img_folder in sorted(os.listdir(ucsf_image_dir)) for img in os.listdir(os.path.join(ucsf_image_dir,img_folder)) ]\n",
    "    \n",
    "    washu_odi=np.load(washu_label)\n",
    "    washu_odi=np.array([item>40 for item in washu_odi],dtype=np.int32)\n",
    "    washu_odi=list(np.repeat(washu_odi,replicate))\n",
    "    washu_images=[os.path.join(washu_image_dir,img_folder,img) for img_folder in sorted(os.listdir(washu_image_dir)) for img in os.listdir(os.path.join(washu_image_dir,img_folder)) ]\n",
    "    \n",
    "    images=jhu_images+ucsf_images+washu_images\n",
    "    scores=jhu_odi+ucsf_odi+washu_odi\n",
    "    \n",
    "    print(len(images))\n",
    "    print(len(scores))\n",
    "    \n",
    "    return images,scores\n",
    "\n",
    "images,scores=create_aug_dataloaders_resnet(jhu_image_dir='/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_JHU/augmented_images_resnet',ucsf_image_dir='/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_UCSF/augmented_images_resnet',washu_image_dir='/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_WashU/augmented_images_resnet',jhu_label='/home/blu/ai/xray_score/JHU_UCSF_WASHU/jhu.npy',ucsf_label='/home/blu/ai/xray_score/JHU_UCSF_WASHU/ucsf.npy',washu_label='/home/blu/ai/xray_score/JHU_UCSF_WASHU/washu.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create seperate image folders for jhu, washu and ucsf and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using augmented dataset\n",
    "def create_aug_dataloaders_resnet_10(jhu_image_dir=None,ucsf_image_dir=None,washu_image_dir=None,jhu_label=None,ucsf_label=None,washu_label=None,replicate=22):\n",
    "    \n",
    "    jhu_odi=np.load(jhu_label)\n",
    "    jhu_odi=np.array([item>40 for item in jhu_odi],dtype=np.int32)\n",
    "    jhu_odi=list(np.repeat(jhu_odi,replicate))\n",
    "    jhu_images=[os.path.join(jhu_image_dir,img_folder,img) for img_folder in sorted(os.listdir(jhu_image_dir)) for img in os.listdir(os.path.join(jhu_image_dir,img_folder)) ]\n",
    "    \n",
    "    ucsf_odi=np.load(ucsf_label)\n",
    "    ucsf_odi=np.array([item>40 for item in ucsf_odi],dtype=np.int32)\n",
    "    ucsf_odi=list(np.repeat(ucsf_odi,replicate))\n",
    "    ucsf_images=[os.path.join(ucsf_image_dir,img_folder,img) for img_folder in sorted(os.listdir(ucsf_image_dir)) for img in os.listdir(os.path.join(ucsf_image_dir,img_folder)) ]\n",
    "    \n",
    "    washu_odi=np.load(washu_label)\n",
    "    washu_odi=np.array([item>40 for item in washu_odi],dtype=np.int32)\n",
    "    washu_odi=list(np.repeat(washu_odi,replicate))\n",
    "    washu_images=[os.path.join(washu_image_dir,img_folder,img) for img_folder in sorted(os.listdir(washu_image_dir)) for img in os.listdir(os.path.join(washu_image_dir,img_folder)) ]\n",
    "    \n",
    "    images=jhu_images+ucsf_images+washu_images\n",
    "    scores=jhu_odi+ucsf_odi+washu_odi\n",
    "    \n",
    "    print(len(images))\n",
    "    print(len(scores))\n",
    "    \n",
    "    return jhu_images,jhu_odi,ucsf_images,ucsf_odi,washu_images,washu_odi\n",
    "\n",
    "jhu_images,jhu_scores,ucsf_images,ucsf_scores,washu_images,washu_scores=create_aug_dataloaders_resnet_10(jhu_image_dir='/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_JHU/augmented_images_resnet_10',ucsf_image_dir='/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_UCSF/augmented_images_resnet_10',washu_image_dir='/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_WashU/augmented_images_resnet_10',jhu_label='/home/blu/ai/xray_score/JHU_UCSF_WASHU/jhu.npy',ucsf_label='/home/blu/ai/xray_score/JHU_UCSF_WASHU/ucsf.npy',washu_label='/home/blu/ai/xray_score/JHU_UCSF_WASHU/washu.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(jhu_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Resnet\n",
    "#Load the resnet model\n",
    "model=models.resnet50('IMAGENET1K_V2')\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove final classification layer\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the embeddings for each image- store it in np array\n",
    "final_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224), interpolation=Image.LANCZOS),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225])  # Single channel stats\n",
    "        ])\n",
    "\n",
    "def image_embedding_generator(image_paths):\n",
    "    index=0\n",
    "    for img_path in image_paths:\n",
    "        img=Image.open(img_path).convert('RGB')\n",
    "        img=final_transform(img).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            embedding=model(img)\n",
    "            index+=1\n",
    "            print(index,embedding.shape)\n",
    "            embedding=embedding.squeeze().numpy()\n",
    "            yield embedding\n",
    "\n",
    "embeddings=[embedding for embedding in image_embedding_generator(washu_images)]\n",
    "embeddings=np.array(embeddings)\n",
    "print(embeddings.shape)\n",
    "np.save('washu_image_embeddings_aug_resnet_10.npy',embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load torchxray vision\n",
    "#Load the model\n",
    "model=xrv.models.ResNet(weights=\"resnet50-res512-all\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "# Transformation (Resizing to 512x512)\n",
    "transform = torchvision.transforms.Compose([\n",
    "    xrv.datasets.XRayResizer(512)\n",
    "])\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = np.array(Image.open(img_path).convert('L'))\n",
    "    img = xrv.datasets.normalize(img, 255)\n",
    "    img = img[None, :, :]  # Add channel dimension\n",
    "    img = transform(img)  # Resize\n",
    "    return torch.from_numpy(img)\n",
    "\n",
    "def image_embeddings_in_batches(image_paths, batch_size=16):\n",
    "    embeddings = []\n",
    "    batch = []\n",
    "\n",
    "    for img_path in tqdm(image_paths):\n",
    "        img_tensor = load_and_preprocess_image(img_path)\n",
    "        batch.append(img_tensor)\n",
    "\n",
    "        if len(batch) == batch_size:\n",
    "            batch_tensor = torch.stack(batch).to(device)  # (B, 1, 512, 512)\n",
    "            with torch.no_grad():\n",
    "                batch_embedding = model.features(batch_tensor)  # (B, D)\n",
    "            embeddings.append(batch_embedding.cpu().numpy())\n",
    "            batch = []\n",
    "\n",
    "    # Process leftover images\n",
    "    if batch:\n",
    "        batch_tensor = torch.stack(batch).to(device)\n",
    "        with torch.no_grad():\n",
    "            batch_embedding = model.features(batch_tensor)\n",
    "        embeddings.append(batch_embedding.cpu().numpy())\n",
    "\n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "    return embeddings\n",
    "\n",
    "embeddings = image_embeddings_in_batches(images, batch_size=16)\n",
    "print(embeddings.shape)\n",
    "np.save('image_embeddings_aug_torchxray.npy', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "#Loading the embeddings into a list and performing split\n",
    "#image_embeddings=np.load('image_embeddings_aug_torchxray.npy').tolist()\n",
    "jhu_embeddings=np.load('jhu_image_embeddings_aug_resnet_10.npy')\n",
    "ucsf_embeddings=np.load('ucsf_image_embeddings_aug_resnet_10.npy')\n",
    "washu_embeddings=np.load('washu_image_embeddings_aug_resnet_10.npy')\n",
    "image_embeddings=np.vstack((jhu_embeddings,ucsf_embeddings,washu_embeddings)).tolist()\n",
    "image_labels=jhu_scores+ucsf_scores+washu_scores\n",
    "# image_embeddings=np.load('image_embeddings_aug_resnet.npy').tolist()\n",
    "# image_labels=scores\n",
    "# image_embeddings=image_embeddings[:-940]\n",
    "# image_labels=image_labels[:-940]\n",
    "print(len(image_embeddings))\n",
    "print(len(image_labels))\n",
    "#Split the data\n",
    "train_embeddings,test_embeddings,train_labels,test_labels=train_test_split(image_embeddings,image_labels,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=10,class_weight='balanced', random_state=40)\n",
    "rf_clf.fit(train_embeddings, train_labels)\n",
    "rf_predictions = rf_clf.predict(test_embeddings)\n",
    "print(classification_report(test_labels, rf_predictions))\n",
    "print(confusion_matrix(test_labels, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tree = rf_clf.estimators_[0]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree, filled=True, feature_names=None, class_names=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5 Images with Lowest ODI Scores ---\n",
      "Score: 0.00, Path: /mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_WashU/final_images/WUNCPXY0072-TC\n",
      "Score: 4.00, Path: /mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_JHU/JPG/JHUCV0050_CK\n",
      "Score: 6.00, Path: /mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_JHU/JPG/JHUCV0029_CL\n",
      "Score: 6.00, Path: /mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_WashU/final_images/WUNCPXY0010-CJ\n",
      "Score: 10.00, Path: /mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_JHU/JPG/JHUCV0051_CS\n",
      "\n",
      "--- 5 Images with Highest ODI Scores ---\n",
      "Score: 84.00, Path: /mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_UCSF/UCSF/USFCPXY0090-ML\n",
      "Score: 84.00, Path: /mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_UCSF/UCSF/USFCPXY0138-JC\n",
      "Score: 86.00, Path: /mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_UCSF/UCSF/USFCPXY0163-RK\n",
      "Score: 86.00, Path: /mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_UCSF/UCSF/USFCPXY0166-BS\n",
      "Score: 94.00, Path: /mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_UCSF/UCSF/USFCPXY0052-RA\n"
     ]
    }
   ],
   "source": [
    "#Find the 5 highest ODI score images an 5 lowest ones\n",
    "# Find their embeddings\n",
    "# Create the heatmap\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def find_target_images():\n",
    "    \"\"\"\n",
    "    Loads original scores and image paths, then finds the 5 images with\n",
    "    the highest scores and 5 with the lowest scores.\n",
    "    \"\"\"\n",
    "    # Define paths to original data and score files\n",
    "    base_dirs = {\n",
    "        'jhu': '/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_JHU/JPG',\n",
    "        'ucsf': '/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_UCSF/UCSF',\n",
    "        'washu': '/mnt/c/Users/swapnil/Downloads/XRAY_Dataset/XRAY_WashU/final_images'\n",
    "    }\n",
    "    label_files = {\n",
    "        'jhu': '/home/blu/ai/xray_score/JHU_UCSF_WASHU/jhu.npy',\n",
    "        'ucsf': '/home/blu/ai/xray_score/JHU_UCSF_WASHU/ucsf.npy',\n",
    "        'washu': '/home/blu/ai/xray_score/JHU_UCSF_WASHU/washu.npy'\n",
    "    }\n",
    "\n",
    "    all_images_with_scores = []\n",
    "\n",
    "    for key in base_dirs:\n",
    "        # Load the original continuous scores\n",
    "        scores = np.load(label_files[key])\n",
    "        \n",
    "        # Get paths to the original images, skipping the augmented directory\n",
    "        # This assumes original images are in subfolders within the base_dir\n",
    "        image_paths = [\n",
    "            os.path.join(base_dirs[key], img_folder)\n",
    "            for img_folder in sorted(os.listdir(base_dirs[key]))\n",
    "        ]\n",
    "        \n",
    "        # Important: Ensure the number of images matches the number of scores\n",
    "        if len(scores) == len(image_paths):\n",
    "            for i in range(len(scores)):\n",
    "                all_images_with_scores.append((scores[i], image_paths[i]))\n",
    "        else:\n",
    "            print(f\"Warning: Mismatch in {key} dataset. Found {len(image_paths)} images and {len(scores)} scores.\")\n",
    "\n",
    "\n",
    "    # Sort the list based on the score (the first element in the tuple)\n",
    "    all_images_with_scores.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Get the 5 lowest and 5 highest\n",
    "    lowest_5 = all_images_with_scores[:5]\n",
    "    highest_5 = all_images_with_scores[-5:]\n",
    "\n",
    "    print(\"--- 5 Images with Lowest ODI Scores ---\")\n",
    "    for score, path in lowest_5:\n",
    "        print(f\"Score: {score:.2f}, Path: {path}\")\n",
    "\n",
    "    print(\"\\n--- 5 Images with Highest ODI Scores ---\")\n",
    "    for score, path in highest_5:\n",
    "        print(f\"Score: {score:.2f}, Path: {path}\")\n",
    "        \n",
    "    #return lowest_5 + highest_5\n",
    "    return all_images_with_scores\n",
    "\n",
    "\n",
    "# Execute the function to find our 10 target images\n",
    "target_images = find_target_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Heatmaps ---\n",
      "idx: 1\n",
      "idx: 2\n",
      "idx: 3\n",
      "idx: 4\n",
      "idx: 5\n",
      "idx: 6\n",
      "idx: 7\n",
      "idx: 8\n",
      "idx: 9\n",
      "idx: 10\n",
      "idx: 11\n",
      "idx: 12\n",
      "idx: 13\n",
      "idx: 14\n",
      "idx: 15\n",
      "idx: 16\n",
      "idx: 17\n",
      "idx: 18\n",
      "idx: 19\n",
      "idx: 20\n",
      "idx: 21\n",
      "idx: 22\n",
      "idx: 23\n",
      "idx: 24\n",
      "idx: 25\n",
      "idx: 26\n",
      "idx: 27\n",
      "idx: 28\n",
      "idx: 29\n",
      "idx: 30\n",
      "idx: 31\n",
      "idx: 32\n",
      "idx: 33\n",
      "idx: 34\n",
      "idx: 35\n",
      "idx: 36\n",
      "idx: 37\n",
      "idx: 38\n",
      "idx: 39\n",
      "idx: 40\n",
      "idx: 41\n",
      "idx: 42\n",
      "idx: 43\n",
      "idx: 44\n",
      "idx: 45\n",
      "idx: 46\n",
      "idx: 47\n",
      "idx: 48\n",
      "idx: 49\n",
      "idx: 50\n",
      "idx: 51\n",
      "idx: 52\n",
      "idx: 53\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def generate_and_plot_heatmap(image_path, score, cam_model, target_layer):\n",
    "    \"\"\"\n",
    "    Generates and displays a heatmap for a single image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        original_img = Image.open(image_path).convert('RGB')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find image at {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Standard preprocessing for ResNet\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    input_tensor = preprocess(original_img).unsqueeze(0)\n",
    "    \n",
    "    # Generate the heatmap. We pass `targets=None` so Grad-CAM automatically\n",
    "    # picks the class with the highest score from the ImageNet model.\n",
    "    grayscale_cam = cam_model(input_tensor=input_tensor, targets=None)\n",
    "    \n",
    "    # Get the first (and only) heatmap\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    \n",
    "    # Overlay heatmap on a normalized version of the original image\n",
    "    #visualization_img = np.array(original_img.resize((224, 224))) / 255.0\n",
    "    visualization_img = np.array(original_img) / 255.0\n",
    "    resized_heatmap = cv2.resize(grayscale_cam, original_img.size)\n",
    "    cam_image = show_cam_on_image(visualization_img, resized_heatmap, use_rgb=True)\n",
    "    #cam_image = show_cam_on_image(visualization_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "    # # Plot the result\n",
    "    # plt.imshow(cam_image)\n",
    "    # plt.title(f'Score: {score:.2f}\\n{os.path.basename(image_path)}')\n",
    "    # plt.axis('off')\n",
    "    # #plt.show()\n",
    "    # plt.imsave(f'./heatmaps/{score}_{os.path.basename(image_path)}',cam_image)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(cam_image)\n",
    "    #ax.set_title(f'Score: {score:.2f}\\n{os.path.basename(image_path)}')\n",
    "    ax.axis('off')\n",
    "    # 2. Define save path and save the figure\n",
    "    # We use a sanitized filename to avoid issues with paths\n",
    "    filename = f'{score}_{os.path.basename(image_path)}'\n",
    "    save_path = os.path.join('heatmaps', filename)\n",
    "    plt.savefig(save_path,bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    # 3. CRUCIAL STEP: Close the figure to release memory\n",
    "    plt.close(fig)\n",
    "\n",
    "# --- Main Execution for Heatmap Generation ---\n",
    "\n",
    "# 1. Load pre-trained ResNet50 and define the target layer\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "model.eval()\n",
    "target_layer = [model.layer4[-1]] # The last convolutional block\n",
    "\n",
    "# 2. Initialize GradCAM\n",
    "cam = GradCAM(model=model, target_layers=target_layer)\n",
    "os.makedirs('heatmaps',exist_ok=True)\n",
    "# 3. Loop through the 10 selected images and generate a heatmap for each\n",
    "print(\"\\n--- Generating Heatmaps ---\")\n",
    "idx=0\n",
    "if 'target_images' in locals() and target_images:\n",
    "    for score, folder_path in target_images:\n",
    "        idx+=1\n",
    "        print(f'idx: {idx}')\n",
    "        images=os.listdir(folder_path)\n",
    "        #img_path=os.path.join(folder_path,images[1])\n",
    "        for image in images:\n",
    "            img_path=os.path.join(folder_path,image)\n",
    "            generate_and_plot_heatmap(img_path, score, cam, target_layer)\n",
    "else:\n",
    "    print(\"Could not find target images. Please run the first part of the script successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
